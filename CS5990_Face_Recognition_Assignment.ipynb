{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS5990_Face_Recognition_Assignment",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "0LTkJTwm71KA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CS5990: Face Recognition Assignment\n",
        "### Overview:\n",
        "You will be submitting uploading your own video file and images of people onto Google Drive.  The library imported from https://github.com/ageitgey/face_recognition and has been formatted onto Google Colab for your convenience.  Please follow through each code cell and read through the comments if you wish to gain a better understanding of how it works.  Otherwise, simply follow the instructions indicated through comments."
      ]
    },
    {
      "metadata": {
        "id": "M9kjNrj48mUh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### We begin by installing the necessary dependencies for image processing, face detection, and pre-trained models."
      ]
    },
    {
      "metadata": {
        "id": "kgtmnGf9YoSa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install face_recognition_models\n",
        "!pip install dlib\n",
        "!pip install opencv-python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sV32ANBC9TaG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import the installed libraries.\n",
        "#### We also begin importing dlib's pre-trained face detection models as well as pre-trained face_recognition models that produce the 128-dimensional vectors mentioned in the presentation."
      ]
    },
    {
      "metadata": {
        "id": "y9YdVKVCYqx4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import PIL.Image\n",
        "import dlib\n",
        "import numpy as np\n",
        "import face_recognition_models\n",
        "\n",
        "\n",
        "face_detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "predictor_68_point_model = face_recognition_models.pose_predictor_model_location()\n",
        "pose_predictor_68_point = dlib.shape_predictor(predictor_68_point_model)\n",
        "\n",
        "predictor_5_point_model = face_recognition_models.pose_predictor_five_point_model_location()\n",
        "pose_predictor_5_point = dlib.shape_predictor(predictor_5_point_model)\n",
        "\n",
        "cnn_face_detection_model = face_recognition_models.cnn_face_detector_model_location()\n",
        "cnn_face_detector = dlib.cnn_face_detection_model_v1(cnn_face_detection_model)\n",
        "\n",
        "face_recognition_model = face_recognition_models.face_recognition_model_location()\n",
        "face_encoder = dlib.face_recognition_model_v1(face_recognition_model)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uHXwf-LM-A1P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Euclidean Distance (L2) of two 128-d vectors"
      ]
    },
    {
      "metadata": {
        "id": "Iegb2cLW9FkQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def face_distance(face_encodings, face_to_compare):\n",
        "    \"\"\"\n",
        "    Given a list of face encodings, compare them to a known face encoding and get a euclidean distance\n",
        "    for each comparison face. The distance tells you how similar the faces are.\n",
        "\n",
        "    :param faces: List of face encodings to compare\n",
        "    :param face_to_compare: A face encoding to compare against\n",
        "    :return: A numpy ndarray with the distance for each face in the same order as the 'faces' array\n",
        "    \"\"\"\n",
        "    if len(face_encodings) == 0:\n",
        "        return np.empty((0))\n",
        "\n",
        "    return np.linalg.norm(face_encodings - face_to_compare, axis=1)\n",
        "  \n",
        "def compare_faces(known_face_encodings, face_encoding_to_check, tolerance=0.55):\n",
        "    \"\"\"\n",
        "    Compare a list of face encodings against a candidate encoding to see if they match.\n",
        "\n",
        "    :param known_face_encodings: A list of known face encodings\n",
        "    :param face_encoding_to_check: A single face encoding to compare against the list\n",
        "    :param tolerance: How much distance between faces to consider it a match. Lower is more strict. 0.6 is typical best performance.\n",
        "    :return: A list of True/False values indicating which known_face_encodings match the face encoding to check\n",
        "    \"\"\"\n",
        "    return list(face_distance(known_face_encodings, face_encoding_to_check) <= tolerance)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OIt9lkRA-HpD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Convert image to numpy array"
      ]
    },
    {
      "metadata": {
        "id": "RKljTjyy9C37",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_image_file(file, mode='RGB'):\n",
        "    \"\"\"\n",
        "    Loads an image file (.jpg, .png, etc) into a numpy array\n",
        "\n",
        "    :param file: image file name or file object to load\n",
        "    :param mode: format to convert the image to. Only 'RGB' (8-bit RGB, 3 channels) and 'L' (black and white) are supported.\n",
        "    :return: image contents as numpy array\n",
        "    \"\"\"\n",
        "    im = PIL.Image.open(file)\n",
        "    if mode:\n",
        "        im = im.convert(mode)\n",
        "    return np.array(im)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2_ajggKz-RIp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Methods that return bounding boxes of faces, can utilize the different face detection models mentioned:\n",
        "1. Histogram of Oriented Gradients (HOG) [DEFAULT]\n",
        "2. CNN"
      ]
    },
    {
      "metadata": {
        "id": "S8lbI06k5kYs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _raw_face_locations(img, number_of_times_to_upsample=1, model=\"hog\"):\n",
        "    \"\"\"\n",
        "    Returns an array of bounding boxes of human faces in a image\n",
        "\n",
        "    :param img: An image (as a numpy array)\n",
        "    :param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n",
        "    :param model: Which face detection model to use. \"hog\" is less accurate but faster on CPUs. \"cnn\" is a more accurate\n",
        "                  deep-learning model which is GPU/CUDA accelerated (if available). The default is \"hog\".\n",
        "    :return: A list of dlib 'rect' objects of found face locations\n",
        "    \"\"\"\n",
        "    if model == \"cnn\":\n",
        "        return cnn_face_detector(img, number_of_times_to_upsample)\n",
        "    else:\n",
        "        return face_detector(img, number_of_times_to_upsample)\n",
        "\n",
        "def face_locations(img, number_of_times_to_upsample=1, model=\"hog\"):\n",
        "    \"\"\"\n",
        "    Returns an array of bounding boxes of human faces in a image\n",
        "\n",
        "    :param img: An image (as a numpy array)\n",
        "    :param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n",
        "    :param model: Which face detection model to use. \"hog\" is less accurate but faster on CPUs. \"cnn\" is a more accurate\n",
        "                  deep-learning model which is GPU/CUDA accelerated (if available). The default is \"hog\".\n",
        "    :return: A list of tuples of found face locations in css (top, right, bottom, left) order\n",
        "    \"\"\"\n",
        "    if model == \"cnn\":\n",
        "        return [_trim_css_to_bounds(_rect_to_css(face.rect), img.shape) for face in _raw_face_locations(img, number_of_times_to_upsample, \"cnn\")]\n",
        "    else:\n",
        "        return [_trim_css_to_bounds(_rect_to_css(face), img.shape) for face in _raw_face_locations(img, number_of_times_to_upsample, model)]\n",
        "\n",
        "def _raw_face_locations_batched(images, number_of_times_to_upsample=1, batch_size=128):\n",
        "    \"\"\"\n",
        "    Returns an 2d array of dlib rects of human faces in a image using the cnn face detector\n",
        "\n",
        "    :param img: A list of images (each as a numpy array)\n",
        "    :param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n",
        "    :return: A list of dlib 'rect' objects of found face locations\n",
        "    \"\"\"\n",
        "    return cnn_face_detector(images, number_of_times_to_upsample, batch_size=batch_size)\n",
        "  \n",
        "def batch_face_locations(images, number_of_times_to_upsample=1, batch_size=128):\n",
        "    \"\"\"\n",
        "    Returns an 2d array of bounding boxes of human faces in a image using the cnn face detector\n",
        "    If you are using a GPU, this can give you much faster results since the GPU\n",
        "    can process batches of images at once. If you aren't using a GPU, you don't need this function.\n",
        "\n",
        "    :param img: A list of images (each as a numpy array)\n",
        "    :param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n",
        "    :param batch_size: How many images to include in each GPU processing batch.\n",
        "    :return: A list of tuples of found face locations in css (top, right, bottom, left) order\n",
        "    \"\"\"\n",
        "    def convert_cnn_detections_to_css(detections):\n",
        "        return [_trim_css_to_bounds(_rect_to_css(face.rect), images[0].shape) for face in detections]\n",
        "\n",
        "    raw_detections_batched = _raw_face_locations_batched(images, number_of_times_to_upsample, batch_size)\n",
        "\n",
        "    return list(map(convert_cnn_detections_to_css, raw_detections_batched))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j3dUKdHQ-ypI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Methods Obtain coordinates of facial landmarks\n",
        "These landmarks can be used for many different tasks including:\n",
        "1. Facial Recognition\n",
        "2. Emotion Classification\n",
        "3. Digital Makeup"
      ]
    },
    {
      "metadata": {
        "id": "O9gGlTNr5Xny",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _raw_face_landmarks(face_image, face_locations=None, model=\"large\"):\n",
        "    if face_locations is None:\n",
        "        face_locations = _raw_face_locations(face_image)\n",
        "    else:\n",
        "        face_locations = [_css_to_rect(face_location) for face_location in face_locations]\n",
        "\n",
        "    pose_predictor = pose_predictor_68_point\n",
        "\n",
        "    if model == \"small\":\n",
        "        pose_predictor = pose_predictor_5_point\n",
        "\n",
        "    return [pose_predictor(face_image, face_location) for face_location in face_locations]\n",
        "  \n",
        "def face_landmarks(face_image, face_locations=None, model=\"large\"):\n",
        "    \"\"\"\n",
        "    Given an image, returns a dict of face feature locations (eyes, nose, etc) for each face in the image\n",
        "\n",
        "    :param face_image: image to search\n",
        "    :param face_locations: Optionally provide a list of face locations to check.\n",
        "    :param model: Optional - which model to use. \"large\" (default) or \"small\" which only returns 5 points but is faster.\n",
        "    :return: A list of dicts of face feature locations (eyes, nose, etc)\n",
        "    \"\"\"\n",
        "    landmarks = _raw_face_landmarks(face_image, face_locations, model)\n",
        "    landmarks_as_tuples = [[(p.x, p.y) for p in landmark.parts()] for landmark in landmarks]\n",
        "\n",
        "    # For a definition of each point index, see https://cdn-images-1.medium.com/max/1600/1*AbEg31EgkbXSQehuNJBlWg.png\n",
        "    if model == 'large':\n",
        "        return [{\n",
        "            \"chin\": points[0:17],\n",
        "            \"left_eyebrow\": points[17:22],\n",
        "            \"right_eyebrow\": points[22:27],\n",
        "            \"nose_bridge\": points[27:31],\n",
        "            \"nose_tip\": points[31:36],\n",
        "            \"left_eye\": points[36:42],\n",
        "            \"right_eye\": points[42:48],\n",
        "            \"top_lip\": points[48:55] + [points[64]] + [points[63]] + [points[62]] + [points[61]] + [points[60]],\n",
        "            \"bottom_lip\": points[54:60] + [points[48]] + [points[60]] + [points[67]] + [points[66]] + [points[65]] + [points[64]]\n",
        "        } for points in landmarks_as_tuples]\n",
        "    elif model == 'small':\n",
        "        return [{\n",
        "            \"nose_tip\": [points[4]],\n",
        "            \"left_eye\": points[2:4],\n",
        "            \"right_eye\": points[0:2],\n",
        "        } for points in landmarks_as_tuples]\n",
        "    else:\n",
        "        raise ValueError(\"Invalid landmarks model type. Supported models are ['small', 'large'].\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZZu58XIa_Jdq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Retrieve the 128-d vector given facial landmarks and face_image."
      ]
    },
    {
      "metadata": {
        "id": "jObs3kPB5Xyt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def face_encodings(face_image, known_face_locations=None, num_jitters=1):\n",
        "    \"\"\"\n",
        "    Given an image, return the 128-dimension face encoding for each face in the image.\n",
        "\n",
        "    :param face_image: The image that contains one or more faces\n",
        "    :param known_face_locations: Optional - the bounding boxes of each face if you already know them.\n",
        "    :param num_jitters: How many times to re-sample the face when calculating encoding. Higher is more accurate, but slower (i.e. 100 is 100x slower)\n",
        "    :return: A list of 128-dimensional face encodings (one for each face in the image)\n",
        "    \"\"\"\n",
        "    raw_landmarks = _raw_face_landmarks(face_image, known_face_locations, model=\"small\")\n",
        "    return [np.array(face_encoder.compute_face_descriptor(face_image, raw_landmark_set, num_jitters)) for raw_landmark_set in raw_landmarks]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MG23_TIa_ncK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _rect_to_css(rect):\n",
        "    \"\"\"\n",
        "    Convert a dlib 'rect' object to a plain tuple in (top, right, bottom, left) order\n",
        "\n",
        "    :param rect: a dlib 'rect' object\n",
        "    :return: a plain tuple representation of the rect in (top, right, bottom, left) order\n",
        "    \"\"\"\n",
        "    return rect.top(), rect.right(), rect.bottom(), rect.left()\n",
        "\n",
        "\n",
        "def _css_to_rect(css):\n",
        "    \"\"\"\n",
        "    Convert a tuple in (top, right, bottom, left) order to a dlib `rect` object\n",
        "\n",
        "    :param css:  plain tuple representation of the rect in (top, right, bottom, left) order\n",
        "    :return: a dlib `rect` object\n",
        "    \"\"\"\n",
        "    return dlib.rectangle(css[3], css[0], css[1], css[2])\n",
        "\n",
        "\n",
        "def _trim_css_to_bounds(css, image_shape):\n",
        "    \"\"\"\n",
        "    Make sure a tuple in (top, right, bottom, left) order is within the bounds of the image.\n",
        "\n",
        "    :param css:  plain tuple representation of the rect in (top, right, bottom, left) order\n",
        "    :param image_shape: numpy shape of the image array\n",
        "    :return: a trimmed plain tuple representation of the rect in (top, right, bottom, left) order\n",
        "    \"\"\"\n",
        "    return max(css[0], 0), min(css[1], image_shape[1]), min(css[2], image_shape[0]), max(css[3], 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E1mYUBDLt-Xg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7YeB5jzJucWV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%cd drive/My\\ Drive/College/DL\\ ML/FR_Presentation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N0tbPnM_vVfq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ucTnqFlqsFHF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageDraw\n",
        "\n",
        "# This is an example of running face recognition on a single image\n",
        "# and drawing a box around each person that was identified.\n",
        "\n",
        "# Load a sample picture and learn how to recognize it.\n",
        "dst_image = load_image_file(\"DST.jpg\")\n",
        "dst_face_encoding = face_encodings(dst_image)[0]\n",
        "\n",
        "# Load a second sample picture and learn how to recognize it.\n",
        "js_image = load_image_file(\"JS.jpg\")\n",
        "js_face_encoding = face_encodings(js_image)[0]\n",
        "\n",
        "# Create arrays of known face encodings and their names\n",
        "known_face_encodings = [\n",
        "    dst_face_encoding,\n",
        "    js_face_encoding\n",
        "]\n",
        "known_face_names = [\n",
        "    \"Danaerys Targaeryen\",\n",
        "    \"Jon Snow\"\n",
        "]\n",
        "\n",
        "# Load an image with an unknown face\n",
        "unknown_image = load_image_file(\"DAJ.jpg\")\n",
        "\n",
        "# Find all the faces and face encodings in the unknown image\n",
        "list_face_locations = face_locations(unknown_image)\n",
        "list_face_encodings = face_encodings(unknown_image, list_face_locations)\n",
        "\n",
        "# Convert the image to a PIL-format image so that we can draw on top of it with the Pillow library\n",
        "# See http://pillow.readthedocs.io/ for more about PIL/Pillow\n",
        "pil_image = Image.fromarray(unknown_image)\n",
        "# Create a Pillow ImageDraw Draw instance to draw with\n",
        "draw = ImageDraw.Draw(pil_image)\n",
        "\n",
        "# Loop through each face found in the unknown image\n",
        "for (top, right, bottom, left), face_encoding in zip(list_face_locations, list_face_encodings):\n",
        "    # See if the face is a match for the known face(s)\n",
        "    matches = compare_faces(known_face_encodings, face_encoding)\n",
        "\n",
        "    name = \"Unknown\"\n",
        "\n",
        "    # If a match was found in known_face_encodings, just use the first one.\n",
        "    if True in matches:\n",
        "        first_match_index = matches.index(True)\n",
        "        name = known_face_names[first_match_index]\n",
        "\n",
        "    # Draw a box around the face using the Pillow module\n",
        "    draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))\n",
        "\n",
        "    # Draw a label with a name below the face\n",
        "    text_width, text_height = draw.textsize(name)\n",
        "    draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255))\n",
        "    draw.text((left + 6, bottom - text_height - 5), name, fill=(255, 255, 255, 255))\n",
        "\n",
        "\n",
        "# Remove the drawing library from memory as per the Pillow docs\n",
        "del draw\n",
        "\n",
        "# Display the resulting image\n",
        "pil_image.show()\n",
        "\n",
        "# You can also save a copy of the new image to disk if you want by uncommenting this line\n",
        "# pil_image.save(\"image_with_boxes.jpg\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "atrBroSGsUGz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}